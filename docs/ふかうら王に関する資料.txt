
ふかうら王に関する資料

ふかうら王は、dlshogi互換エンジンとして2020年12月に開発をスタートしました。


■　dlshogiについて


- dlshogi GitHub : https://github.com/TadaoYamaoka/DeepLearningShogi
- TadaoYamaokaの日記 : https://tadaoyamaoka.hatenablog.com/

- dlshogiの環境構築手順
  - Linux // dlshogiの環境構築手順 : https://tadaoyamaoka.hatenablog.com/entry/2020/05/05/172132 
  - Linux // dlshogiをAWSのNVIDIA A100インスタンスで動かす : https://tadaoyamaoka.hatenablog.com/entry/2020/11/07/154352
  - WSL 2 //
    // k_kanouさんより
    //  CUDA on WSL 2 でもdlshogi の環境構築できました。
    //  NVIDIA Drivers for CUDA on WSL だと、以下にcuda のライブラリが配置されるのが注意点です。
    //  /usr/lib/wsl/lib/libcuda.so.1
    - 待ってました CUDA on WSL 2 : https://qiita.com/ksasaki/items/ee864abd74f95fea1efa
  - Windows :
    - ONNX RUNTIME版はWindows標準で動作するはず。パフォーマンスは劣るけども。
      - ONNX Runtimeを使ってみる : https://tadaoyamaoka.hatenablog.com/entry/2020/05/26/233159
        > dlshogiはCUDAに対応したNvidiaのGPUが必須になっているが、AMDのGPUやCPUのみでも動かせるようにしたいと思っている。
      - ONNX Runtimeを使ってみる その2(性能測定) : https://tadaoyamaoka.hatenablog.com/entry/2020/06/06/190259
      - ONNX Runtimeを使ってみる その3(DirectML) : https://tadaoyamaoka.hatenablog.com/entry/2020/06/07/113616

      // あと、"DirectML.dll"もなぜか実行時に必要らしい。
      // 上の記事「その3(DirectML)」によると、dlshogiの実行ファイルからコピーしてくるとよいようだ。
      // 世界将棋AI 電竜戦バージョン（「GCT電竜」同梱） : https://github.com/TadaoYamaoka/DeepLearningShogi/releases/tag/denryu2020

    - TensorRT版
      - 世界将棋AI 電竜戦バージョン（「GCT電竜」同梱）: https://github.com/TadaoYamaoka/DeepLearningShogi/releases/tag/denryu2020
      // TensorRTはCUDAを最適化するものらしく、CUDAのToolkitも必要。

      - CUDA Toolkit 11.0 Download : https://developer.nvidia.com/cuda-11.0-download-archive
      - WindowsでTensorRTを動かす : https://tadaoyamaoka.hatenablog.com/entry/2020/04/12/155648
          > なお、リリースノートによれば、Windowsでは、パフォーマンスが30%落ちるようである。
          > TCCモードに変更すれば、10%に抑えられると書かれている
      - TensorRTのインストール
        - ↓からdownloadをクリックして会員登録が必要っぽい。2020/12/18現在 TensorRT 7.2.1が最新。
        - https://developer.nvidia.com/tensorrt
        - TensorRT7 download(会員登録後) : https://developer.nvidia.com/nvidia-tensorrt-7x-download
        - NVIDIA TENSORRT DOCUMENTATION : https://docs.nvidia.com/deeplearning/tensorrt/archives/index.html#trt_7

      - cuDNN 8.0.5 ダウンロード(会員登録後) : https://developer.nvidia.com/rdp/cudnn-download
        > Download cuDNN v8.0.5 (November 9th, 2020), for CUDA 11.1
        →　dlshogi、cuDNNは不要になった。[2021/1/25]


■ AobaZeroについて


- AobaZeroの公式サイト : http://www.yss-aya.com/aobazero/
- AobaZeroのGitHub : https://github.com/kobanium/aobazero
- AobaZeroで生成した棋譜(GoogleDrive) : https://drive.google.com/drive/folders/1dbE5xWGQLsduR00oxEGPpZQJtQr_EQ75
  - 日々追加されている。教師棋譜としてそのまま使える。ありがたい。

- AobaZeroの棋譜の加工 : https://tadaoyamaoka.hatenablog.com/entry/2020/11/28/113312
  - AobaZeroの棋譜の勝敗情報を5手詰めを呼び出して修正する。

- aoba_to_hcpe.py : https://github.com/TadaoYamaoka/DeepLearningShogi/blob/master/utils/aoba_to_hcpe.py
  - AobaZeroの棋譜の勝敗情報の加工スクリプト
  - cshogiを使ったスクリプト。
  > 711ファイルの変換を行った。4時間43分で変換できた。
    // 5手詰め
  - 並列化したい＆df-pnを呼び出したいので、同等のものをやねうら王のほうでも独自に実装する。


■　dlshogiの定跡生成手順について


https://github.com/TadaoYamaoka/DeepLearningShogi/tree/master/usi


-DMAKE_BOOK
を付けてビルドして、

./usi
setoption name DNN_Model value /home/ubuntu/model-0000167.onnx
setoption name UCT_Threads value 3
setoption name UCT_Threads2 value 3
setoption name UCT_Threads3 value 3
setoption name UCT_Threads4 value 3
setoption name UCT_Threads5 value 3
setoption name UCT_Threads6 value 3
setoption name UCT_Threads7 value 3
setoption name UCT_Threads8 value 3
setoption name Save_Book_Interval value 100
isready
make_book [bookFileName] [outFileName] [playoutNum] [limitTrialNum]

※
Save_Book_Intervalは、途中で保存する間隔(デフォルト100)
bookFileNameは、対戦相手が使用する定跡を指定します。
outFileNameは、ファイルがないと作られます。すでにあると続きから探索します。
playoutNumは、10000000（1千万）
limitTrialNumは、500
にして、時間のある限り何回も実行しています。
基本はメモリが許す限り探索しています。


rubyスクリプトでは、

https://github.com/TadaoYamaoka/shogi-server/blob/master/bin/usiToCsa_denryu
UCT_NodeLimit=50000000
本番で3分くらい思考する場合があるので、hashfullにならない十分な大きさにしています。
GitHub
TadaoYamaoka/DeepLearningShogi
Contribute to TadaoYamaoka/DeepLearningShogi development by creating an account on GitHub.

GitHub
TadaoYamaoka/shogi-server
Contribute to TadaoYamaoka/shogi-server development by creating an account on GitHub.



■　学習手法


// まとめちゅう
- SoTAを総なめ！衝撃のオプティマイザー「SAM」爆誕&解説！ : https://qiita.com/omiita/items/f24e4f06ae89115d248e


■　指し手のランダム性について


- PUCTだと指し手にランダム性がなく、自己対局では同一の棋譜になりやすい。

- dlshogiでは、ランダム性を持たせるために、強化学習時にはディリクレノイズを使っている。
  - 将棋でディープラーニングする その51(ディリクレノイズ) : https://tadaoyamaoka.hatenablog.com/?page=1515162256


■　dlshogiの学習環境の構築手順 Windowsネイティブ環境


- Windows環境用はGCTの加納さんのノートに詳しい
  GCT (Google Colab TPU Training) 将棋 : https://gist.github.com/lvisdd/9b49ab88600fa242f2138fad4eb06caf
  dlshogi-DenryuSen-resnet10_swish-amp.ipynb : https://colab.research.google.com/drive/1beq7ncmE16lIvOhGTHLzxOwaQNzAcUqh?usp=sharing


■　dlshogiの学習環境の構築手順 Windows環境で、WSL2 + Ubuntu 20.04を使う方法


※　WSL2でGPUが利用できないという問題があったが、ビルド 20236で修正された。
※　WSL2は、現状、Windows Insider Programからのダウンロードが必須。


・Ubuntuをインストールするまで

	# Windowsの設定 - 更新とセキュリティ - Windows Insider Program に参加、 Devチャネルを購読する設定をしてWindowsを更新

	// 参考記事)
	//	待ってました CUDA on WSL 2
	//	https://qiita.com/ksasaki/items/ee864abd74f95fea1efa

	# PowerShell （"Win"+"X"キー or 「Windowsスタートボタン」を右クリックor長押しタップ） → （"I"キー or 「Windows PowerShell(I)」を選択） で起動

	# Cドライブに "c:\wsl"というフォルダを作成。(ここでいまからUbuntu 20.04を動かす)
	mkdir C:\WSL
	cd C:\WSL

	## バージョンナンバーが Windows 10.0.20236.* 以降である事を確認する（2021年2月6日現在、Insider Preview, Dev Channelでのみ可能）
	cmd /c ver

	// TensorRTとCUDAのドライバをダウンロード

	## 以下のページから「TensorRT 7.2.2 for Ubuntu 18.04 and CUDA 11.1 & 11.2 DEB local repo package」を選択して「C:\WSL」にダウンロード
	start https://developer.nvidia.com/nvidia-tensorrt-7x-download
	// ファイル名は→"nv-tensorrt-repo-ubuntu1804-cuda11.1-trt7.2.2.3-ga-20201211_1-1_amd64.deb"のはず。

	# CUDAドライバのダウンロード
	curl.exe -RLO https://developer.download.nvidia.com/compute/cuda/11.2.0/local_installers/cuda-repo-wsl-ubuntu-11-2-local_11.2.0-1_amd64.deb	curl.exe -RLO https://developer.download.nvidia.com/compute/cuda/11.1.1/local_installers/cuda-repo-wsl-ubuntu-11-1-local_11.1.1-1_amd64.deb
	curl.exe -RLO https://developer.download.nvidia.com/compute/cuda/11.2.0/local_installers/cuda-repo-wsl-ubuntu-11-2-local_11.2.0-1_amd64.deb
	// "curl"だけだと、PowerShellのaliasに誤爆する。"curl.exe"と書かないと駄目。

	## NVIDIA CUDA on WSL Public Preview の案内ページをブラウザで開く
	## 「Get CUDA Driver」 のリンクボタンから辿ってWSL対応ドライバを取得、インストールする
	start https://developer.nvidia.com/cuda/wsl
	// "465.42_gameready_win10-dch_64bit_international.exe"
	// これはWindows側で実行してインストールする。

	## NVIDIA Driver のバージョンを確認(2021年2月6日現在、WSL対応ドライバのバージョンは 465.42)
	nvidia-smi

	## (Dev Channelに参加していない場合)
	## 設定: Windows Insider Program を開く。
	## 設定が開いたら、 Windows Insider Program の Dev Channel に参加する。
	## 下記のコマンドで「設定 - Windows Insider Program」を開けない場合：
	## - "Win"+"X" キー → "N"キー で「設定」を開く
	## - 「設定」→（「ホーム」→）「更新とセキュリティ」→「Windows Insider Program」
	start ms-settings:windowsinsider


	## WSL Ubuntu-20.04 のインストール(管理者権限必要)
	wsl --install -d Ubuntu-20.04
	// このあと再起動が必要。
	// 再起動するとUbuntuのインストールが始まる。

	## "Enter new UNIX username:" Ubuntu-20.04用のユーザ名を入力
	## "New password:" Ubuntu-20.04用のパスワードを入力
	## "Retype new password:" Ubuntu-20.04用のパスワードをもう一度入力
	## "Installation succesful!" などと表示されたら成功

	// ## 一旦、WSL Ubuntu-20.04 を終了させる
	// exit

・次回以降のWSLの起動方法

	// # PowerShell 例: "Win"+"X"キー → "I"キー で起動

	## WSL Ubuntu-20.04 を起動
	wsl -d Ubuntu-20.04 --cd ~

	// ## WSLをシャットダウンさせる（この後の手順でネットワークに接続できないなどのトラブルを予防するため）
	// wsl --shutdown

	// ## WSL Ubuntu-20.04 の登録解除
	// wsl --unregister Ubuntu-20.04
	// ## Ubuntu-20.04の起動
	// # WSL Ubuntu-20.04


・WSL Ubuntu-20.04のなかでTensorRTやCUDA環境を構築

	# WSL Ubuntu-20.04
	## Ubuntu APT Mirrors
	## Ubuntuの新規/更新パッケージインストール時間短縮のため、ミラーサイト経由でパッケージ更新できるようにする。
	## sudoで始まるコマンド実行時は、パスワードを要求されることがあるので先に設定したパスワードを入力する。
	sudo sed -i.bak -r 's!(deb|deb-src) http://archive\.ubuntu\.com/\S+!\1 mirror://mirrors.ubuntu.com/mirrors.txt!' /etc/apt/sources.list
	## CUDA導入準備
	curl -RLO https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin
	sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600
	sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/7fa2af80.pub
	## CUDA 11.1.1 for Linux WSL-Ubuntu local repos
	sudo dpkg -i /mnt/c/WSL/cuda-repo-wsl-ubuntu-11-1-local_11.1.1-1_amd64.deb
	sudo apt-key add /var/cuda-repo-wsl-ubuntu-11-1-local/7fa2af80.pub
	## CUDA 11.2.0 for Linux WSL-Ubuntu local repos
	sudo dpkg -i /mnt/c/WSL/cuda-repo-wsl-ubuntu-11-2-local_11.2.0-1_amd64.deb
	sudo apt-key add /var/cuda-repo-wsl-ubuntu-11-2-local/7fa2af80.pub
	## TensorRT 7.2.2 for Linux DEB local repos
	sudo dpkg -i /mnt/c/WSL/nv-tensorrt-repo-ubuntu1804-cuda11.1-trt7.2.2.3-ga-20201211_1-1_amd64.deb
	sudo apt-key add /var/nv-tensorrt-repo-cuda11.1-trt7.2.2.3-ga-20201211/7fa2af80.pub
	## APTパッケージのインストール
	sudo apt-get update
	sudo apt-get -y install cuda curl tensorrt build-essential g++-10 unzip libboost-numpy-dev libboost-python-dev libboost-system-dev python3-pip
	## オンライン上のNVIDIAレポジトリを追加
	sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/ /"
	## APTパッケージを更新
	sudo apt-get update
	sudo apt-get -y upgrade


・dlshogi、2020年電竜戦のGCT相当の評価関数を学習するまで , bookの学習

	pushd ~
	curl -RLO https://github.com/TadaoYamaoka/DeepLearningShogi/releases/download/denryu2020/gct-dlshogi-denryu2020.zip
	popd
	mkdir ~/eval
	mkdir ~/book
	unzip ~/gct-dlshogi-denryu2020.zip *.onnx -d ~/eval
	unzip ~/gct-dlshogi-denryu2020.zip book.bin -d ~/book
	cp ~/eval/model-0000167.onnx ~/eval/model.onnx
	# yaneuraou deep
	git clone https://github.com/yaneurao/YaneuraOu.git ~/YaneuraOu
	pushd ~/YaneuraOu/source
	export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/lib/wsl/lib:/usr/lib/x86_64-linux-gnu
	make YANEURAOU_EDITION=YANEURAOU_ENGINE_DEEP_TENSOR_RT clean
	nice make -j$(grep -c processor /proc/cpuinfo) YANEURAOU_EDITION=YANEURAOU_ENGINE_DEEP_TENSOR_RT TARGET_CPU=AVX2 COMPILER=g++-10 EXTRA_CPPFLAGS='-I/usr/local/cuda/include' EXTRA_LDFLAGS='-L/usr/local/cuda/lib64 -L/usr/lib/wsl/lib' normal
	popd
	# dlshogi
	pip3 install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html
	git clone https://github.com/TadaoYamaoka/DeepLearningShogi.git ~/DeepLearningShogi
	pushd ~
	curl -RLO https://gist.githubusercontent.com/mizar/1f36c8c456926460bc8585e2fc631bd7/raw/8b7e831b7570b5165f8ca2425643b4837e88e4a0/dlshogi.diff
	popd
	pushd ~/DeepLearningShogi
	git apply ~/dlshogi.diff
	pip3 install --no-cache-dir -e .
	pip3 install cshogi
	popd
	pushd ~/DeepLearningShogi/make_hcpe_by_self_play
	make clean
	nice make -j$(grep -c processor /proc/cpuinfo)
	popd
	pushd ~/DeepLearningShogi/cppshogi
	make clean
	nice make -j$(grep -c processor /proc/cpuinfo)
	popd
	pushd ~/DeepLearningShogi/usi
	make clean
	nice make -j$(grep -c processor /proc/cpuinfo)
	popd

// 上のMizarさんのpatchにより、学習用のスクリプト(train_rl_policy_with_value_using_hcpe_bootstrap.py)に"--network"を指定して、動的にmodelの構造を
// 変更できるようになっている。
// cf. https://github.com/mizar/dlshogi/tree/feature/network
// ※　現状非公開


・初期学習の例 (model, stateファイルの引き継ぎ無し）
	// 継続学習に比べて、-m [一つ前のモデル名] と -r [一つ前のstate名]の指定がない。
	wsl.exe -d Ubuntu-20.04 python3 ~/DeepLearningShogi/dlshogi/train_rl_policy_with_value_using_hcpe_bootstrap.py teach_d12_suisho2_20201010_hcpe/teach_d12_suisho2_20201010.hcpe.0000 teach_d18_suisho2_20201125_10k.hcpe --network resnet10_swish --model resnet10_swish/model/model-0000 --state resnet10_swish/model/state-0000 --use_amp --log resnet10_swish/log/log.0000 --lr 0.001 --swa_lr 0.001

・継続学習の例（model, stateファイルの引き継ぎ有り）（stateファイルだけ -r オプションでの指定を省略すれば、modelファイルだけ引き継いで学習する事もできる）
	wsl.exe -d Ubuntu-20.04 python3 ~/DeepLearningShogi/dlshogi/train_rl_policy_with_value_using_hcpe_bootstrap.py teach_d12_suisho2_20201010_hcpe/teach_d12_suisho2_20201010.hcpe.0001 teach_d18_suisho2_20201125_10k.hcpe -m resnet10_swish/model/model-0000 -r resnet10_swish/model/state-0000 --network resnet10_swish --model resnet10_swish/model/model-0001 --state resnet10_swish/model/state-0001 --use_amp --log resnet10_swish/log/log.0001 --lr 0.001 --swa_lr 0.001

・モデルファイルのONNX変換の例
	wsl.exe -d Ubuntu-20.04 python3 ~/DeepLearningShogi/dlshogi/convert_model_to_onnx.py --network resnet10_swish resnet10_swish/model/model-0000 resnet10_swish/model/model-0000.onnx

> python3 ~/DeepLearningShogi/dlshogi/train_rl_policy_with_value_using_hcpe_bootstrap.py hcpe/floodgate_teacher_uniq-test-01 hcpe --network resnet15ch192_swish --model resnet15swish/model/model-0000 --state resnet15swish/model/state-0000 --use_amp --log resnet15swish/log/log.0000 --lr 0.001 --swa_lr 0.001




# 初回
# get dlshogi fork
pushd ~/DeepLearningShogi/
git remote add mizar https://github.com/mizar/dlshogi.git
## https経由での git fetch で要求されるパスワードは、GitHubアカウントのパスワードではなくアクセストークンを入力。
## cf. https://docs.github.com/ja/github/authenticating-to-github/creating-a-personal-access-token
git fetch mizar
git checkout mizar/feature/network -b feature/network
popd


# 2回目以降、更新時
# reset to HEAD of mizar/feature/network
pushd ~/DeepLearningShogi/
git fetch mizar
git reset --hard mizar/feature/network
popd


■　dlshogiの学習ログの見方について


学習の時に生成されるログ・ファイルには、例えば次のように記録されている。

	2021/02/17 19:47:01    INFO    epoch = 103, iteration = 951633, train loss avr = 0.65656561, 0.55363852, 0.77022078, 1.28232603, test_loss = 0.87752425, 0.56018966, 0.60538296, 1.45276328, test accuracy = 0.44430245, 0.72181578, test entropy = 1.51603591, 0.64071724

このそれぞれの意味について、山岡さんから教えていただいた。

	4つのlossはそれぞれ、policy, value(報酬), Q値(探索結果のvalue期待値), 合計です。
	accuracyはそれぞれ、policy, valueの正解率です。
	test entropyは、test局面を推論した際のpolicyとvalueのエントロピー(値がどれだけばらけているか)です。


■　Google Colabの活用


Google ColabがCUDA 11.0対応になったので色々動くようになったようだ。

	dlshogiのLinuxでのビルド/自己対局(で教師局面の生成)の実行方法(加納さんのノート)
	https://colab.research.google.com/drive/14R6rKkBVVZ_lv78h97zC9Zan62KQok-b?usp=sharing


■　ふかうら王で大会に出る人向けの資料


- ふかうら王で大会に出る人に注意点

	- A100*8を借りるとしてエンジンオプションは、以下のように設定する。

		"MaxMovesToDraw" → WCSCは320手引き分けらしいので安全を見て322に。

		"UCT_NodeLimit" →　1億ぐらいに。(搭載メモリに合わせて設定)

		// ResNet10ブロックのmodelファイルを使うとして、
		"UCT_Threads1"  → 4か5がたぶんベスト。
		"DNN_Batch_Size1" → 128ぐらいがベスト。
		"LeafDfpnNodesLimit" →　40ぐらいにしとかないとメモリ帯域食い尽くす。
		"RootMateSearchNodesLimit" →　デフォルトの100万
			解図したときにメモリに記憶してないため、この値を上げると→詰将棋解けた→大駒ただ捨て→相手が指す
			→持ち時間がなくて詰みが見つからん　みたいになって自爆しかねない。
			最小持ち時間(2秒)で絶対に解ける範囲の値のほうがいいのではないかと考えている。
			// 比較実験すべき

		// 持ち時間制御
		"Stochastic_Ponder" → true
		"SlowMover" → 100

		// 千日手打開

		"DrawValueBlack" →　千日手を打開したいなら、両方 496とかに。千日手を狙いたいなら、520ぐらいに。
		"DrawValueWhite"
		(※　評価値はシグモイド関数で勝率に変換できる。評価値-10は、1/(1+EXP(--10/600)) == 0.495833)
